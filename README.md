# Enhancing Wireless Capsule Endoscopy Images

## Description 
This repository contains the code and supplementary files for my research article titled "[Enhancing Wireless Capsule Endoscopy images from intense illumination specular reflections using the homomorphic filter]".

Online version (https://www.sciencedirect.com/science/article/abs/pii/S1746809423001568). 

## Abstract 

Wireless Capsule Endoscopy (WCE) is a non-invasive medical imaging device that gastroenterologists use to investigate gastrointestinal tract disorders. WCE images often suffer from specular reflections (SRs). SR is an outcome of the rigorous light and luminous regions emerging in WCE images, impacting the performance of abnormality detection approaches and physician analysis. The current study aims to invent a method that can automatically segment and eliminate SRs in WCE images to increase the accuracy of abnormality detection approaches and help physicians to make a potent diagnosis. In this study, we introduce a novel method for SR elimination with a negligible damage to the image texture using a homomorphic filter. The proposed method encompasses three steps. Initially, we utilize a robust segmentation technique using the U-Net model to segment SRs based on semantic segmentation. Then, we use the homomorphic filter to separate the illumination and reflection components. Damage caused by SR has different effects on these two components. Our proposed method enhances each of these components separately instead of enhancing the whole image uniformly. Eventually, we reconstruct SR regions using the Navier Stokes inpainting technique based on fluid dynamics. Our experiments were conducted on three different types of WCE datasets. The evaluations were performed with the following criteria accuracy, false negative rate, false positive rate, precision, recall, and F-Measure. The results show that our proposed method eliminates SRs admirably and quantitatively increases the accuracy of the stateof-the-art abnormality detection methods in WCE and improves their performance.

## Contributions and novelties 
• Proposing an approach for the elimination of SR from WCE images with minimal damage to the inherent information of the image using HF.
• A U-Net model based on binary semantic segmentation is proposed to segment SR in WCE images. This model only focuses on the SR pixels, not the other pixels in the image.
• A Navier-Stokes inpainting technique is used to reconstruct the SR regions. The proposed technique reconstructs the SR region by selecting the most well-suited value from adjacent pixels.

## Material and method
This part consists of three parts:
### Proposed U-Net structure for SR segmentation:
We utilize RGB images with 256 × 256 pixels for the proposed model input. Since the proposed model provides a binary mask, the input and output sizes of the model must be the same. Accordingly, the model’s output produces a single-channel image with 256 × 256 pixels. The network architecture is demonstrated in Fig. 4. We established four convolution blocks (CONV) in each encoder and decoder path for our UNet model. The encoder blocks involve two 3 × 3 CONV layers, and each CONV layer is followed by batch normalization and rectified linear unit (ReLU) activation layer. There is a 2 × 2 max-pooling layer with stride 2 for down sampling after each CONV block. The number of feature maps is doubled at each down-sampling stage. The bottleneck layer uses two 3 × 3 CONV layers followed by a 2 × 2 up-convolution layer. Each block includes two 3 × 3 CONV layers in the decoder path that receives input. There is a concatenation with corresponding block feature maps in the encoder path, which is appended as input to each decoder block. After each block, a 2 × 2 up-convolution layer is used for up-sampling and halving the feature map. At the last layer, a 1 × 1 convolution layer with a sigmoid activation is utilized for mapping every 64-component feature vector to the intended number of classes. Eventually, a threshold will be applied to convert the image to a binary mask.
